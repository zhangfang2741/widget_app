import streamlit as st
import pandas as pd
import numpy as np
import requests
import time
import pickle
import os
import datetime
from pathlib import Path

from st_aggrid import AgGrid, GridOptionsBuilder, JsCode

# --- 1. é…ç½® ---
TIINGO_API_KEY = "302c6b2a5781f2b0831b324870f217944ced68e6"
CACHE_DIR = Path("tiingo_ticker_cache")
CACHE_DIR.mkdir(exist_ok=True)
CHINESE_NAMES = {
    # 01 ä¿¡æ¯æŠ€æœ¯
    "XLK": "ç§‘æŠ€è¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "VGT": "å…ˆé”‹ä¿¡æ¯æŠ€æœ¯ETF-Vanguard",
    "SMH": "åŠå¯¼ä½“æŒ‡æ•°ETF-VanEck",
    "IGV": "è½¯ä»¶æœåŠ¡æŒ‡æ•°ETF-iShares",
    # 02 åŒ»ç–—ä¿å¥
    "XLV": "åŒ»ç–—ä¿å¥è¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "IBB": "çº³æ–¯è¾¾å…‹ç”Ÿç‰©æŠ€æœ¯ETF-iShares",
    "XBI": "æ ‡æ™®ç”Ÿç‰©æŠ€æœ¯ETF-SPDR",
    "IHI": "åŒ»ç–—å™¨æ¢°æŒ‡æ•°ETF-iShares",
    # 03 é‡‘è
    "XLF": "é‡‘èè¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "KBE": "æ ‡æ™®é“¶è¡ŒETF-SPDR",
    "KRE": "æ ‡æ™®åœ°åŒºé“¶è¡ŒETF-SPDR",
    "IAI": "è¯åˆ¸ç»çºªå•†æŒ‡æ•°ETF-iShares",
    # 04 å¯é€‰æ¶ˆè´¹
    "XLY": "å¯é€‰æ¶ˆè´¹è¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "XRT": "æ ‡æ™®é›¶å”®æŒ‡æ•°ETF-SPDR",
    "PEJ": "ä¼‘é—²å¨±ä¹æŒ‡æ•°ETF-Invesco",
    # 05 å¿…éœ€æ¶ˆè´¹
    "XLP": "å¿…éœ€æ¶ˆè´¹è¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "VDC": "å…ˆé”‹å¿…éœ€æ¶ˆè´¹ETF-Vanguard",
    "COST": "å¼€å¸‚å®¢(ä¸ªè‚¡)",
    # 06 å·¥ä¸š
    "XLI": "å·¥ä¸šè¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "ITA": "èˆªç©ºå›½é˜²æŒ‡æ•°ETF-iShares",
    "JETS": "å…¨çƒèˆªç©ºä¸šETF-US Global",
    "PAVE": "åŸºç¡€å»ºè®¾æŒ‡æ•°ETF-Global X",
    # 07 èƒ½æº
    "XLE": "èƒ½æºè¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "XOP": "æ ‡æ™®æ²¹æ°”å¼€é‡‡ETF-SPDR",
    "ICLN": "å…¨çƒæ¸…æ´èƒ½æºETF-iShares",
    # 08 åŸææ–™
    "XLB": "åŸææ–™è¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "GLD": "é»„é‡‘ETF-SPDR Gold",
    "SLV": "ç™½é“¶ETF-iShares Silver",
    "GDX": "é‡‘çŸ¿è‚¡æŒ‡æ•°ETF-VanEck",
    "COPX": "é“œçŸ¿è‚¡æŒ‡æ•°ETF-Global X",
    # 09 é€šä¿¡æœåŠ¡
    "XLC": "é€šä¿¡æœåŠ¡è¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "VOX": "å…ˆé”‹é€šä¿¡æœåŠ¡ETF-Vanguard",
    "SOCL": "ç¤¾äº¤åª’ä½“æŒ‡æ•°ETF-Global X",
    # 10 æˆ¿åœ°äº§
    "XLRE": "æˆ¿åœ°äº§è¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "VNQ": "å…ˆé”‹æˆ¿åœ°äº§REITs ETF-Vanguard",
    "REZ": "ä½å®…æˆ¿åœ°äº§æŒ‡æ•°ETF-iShares",
    # 11 å…¬ç”¨äº‹ä¸š
    "XLU": "å…¬ç”¨äº‹ä¸šè¡Œä¸šç²¾é€‰æŒ‡æ•°ETF-SPDR",
    "VPU": "å…ˆé”‹å…¬ç”¨äº‹ä¸šETF-Vanguard",
    "NEE": "æ–°çºªå…ƒèƒ½æº(ä¸ªè‚¡)",
    # 12 å¦ç±»/è·¨è¡Œä¸š
    "ARKK": "æ–¹èˆŸåˆ›æ–°ETF-ARK Invest",
    "BITO": "æ¯”ç‰¹å¸ç­–ç•¥ETF-ProShares",
    "MSOS": "å¤§éº»æ ¸å¿ƒETF-AdvisorShares",
}

# è¡Œä¸šå±‚çº§å®šä¹‰ (æ¶µç›–100+ç»†åˆ†)
ETF_LIBRARY = {
    "01 ä¿¡æ¯æŠ€æœ¯": ["XLK", "VGT", "SMH", "IGV"],
    "02 åŒ»ç–—ä¿å¥": ["XLV", "IBB", "XBI", "IHI"],
    "03 é‡‘è": ["XLF", "KBE", "KRE", "IAI"],
    "04 å¯é€‰æ¶ˆè´¹": ["XLY", "XRT", "PEJ"],
    "05 å¿…éœ€æ¶ˆè´¹": ["XLP", "VDC", "COST"],
    "06 å·¥ä¸š": ["XLI", "ITA", "JETS", "PAVE"],
    "07 èƒ½æº": ["XLE", "XOP", "ICLN"],
    "08 åŸææ–™": ["XLB", "GLD", "SLV", "GDX", "COPX"],
    "09 é€šä¿¡æœåŠ¡": ["XLC", "VOX", "SOCL"],
    "10 æˆ¿åœ°äº§": ["XLRE", "VNQ", "REZ"],
    "11 å…¬ç”¨äº‹ä¸š": ["XLU", "VPU", "NEE"],
    "12 è·¨è¡Œä¸š/å¦ç±»": ["ARKK", "BITO", "MSOS"],
}

TICKER_TO_SECTOR = {t: s for s, ts in ETF_LIBRARY.items() for t in ts}
ALL_TICKERS = list(TICKER_TO_SECTOR.keys())

st.set_page_config(layout="wide", page_title="Market_Foldable_Tree")
st.title("ğŸŒ² ç¾å›½è¡Œä¸šèµ„é‡‘æµçƒ­åŠ›å›¾")

# --- 2. ç¼“å­˜ä¸æ•°æ®æŠ“å– (CLVç®—æ³•) ---
def fetch_ticker_data(ticker: str) -> pd.DataFrame | None:
    cache_path = CACHE_DIR / f"{ticker}.pkl"

    # 1) è¯»ç¼“å­˜ï¼šå¿…é¡»åŒ…å« Flow/Date/Tickerï¼Œå¦åˆ™è§†ä¸ºæ— æ•ˆç¼“å­˜ï¼Œèµ°é‡æ–°æ‹‰å–
    if cache_path.exists() and (time.time() - os.path.getmtime(cache_path)) < 86400:
        try:
            with open(cache_path, "rb") as f:
                obj = pickle.load(f)
            if isinstance(obj, pd.DataFrame):
                required = {"Flow", "Date", "Ticker"}
                if required.issubset(set(obj.columns)):
                    return obj
                # ç¼“å­˜æ˜¯æ—§ç»“æ„æˆ–åæ•°æ®ï¼šå¿½ç•¥ï¼Œç»§ç»­èµ°ç½‘ç»œæ‹‰å–è¦†ç›–ç¼“å­˜
        except Exception:
            pass

    start_date = (datetime.datetime.now() - datetime.timedelta(days=365)).strftime("%Y-%m-%d")
    url = f"https://api.tiingo.com/tiingo/daily/{ticker}/prices?startDate={start_date}&token={TIINGO_API_KEY}"

    try:
        r = requests.get(url, timeout=15)
        if r.status_code != 200:
            return None

        df = pd.DataFrame(r.json())
        if df.empty:
            return None

        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date"])

        denom = df["adjHigh"] - df["adjLow"]
        clv = ((df["adjClose"] - df["adjLow"]) - (df["adjHigh"] - df["adjClose"])) / (denom + 1e-9)
        df["Flow"] = clv * (df["adjClose"] * df["volume"])

        res = df[["date", "Flow"]].rename(columns={"date": "Date"})
        res["Ticker"] = ticker

        try:
            with open(cache_path, "wb") as f:
                pickle.dump(res, f)
        except Exception:
            pass

        return res
    except Exception:
        return None


# --- 3. æ„å»ºå¯æŠ˜å æ±‡æ€»æ•°æ®è¡¨ ---
with st.spinner("æ•°æ®å¤„ç†ä¸­..."):
    all_dfs: list[pd.DataFrame] = []

    total = len(ALL_TICKERS)
    progress = st.progress(0)
    status = st.empty()

    for i, ticker in enumerate(ALL_TICKERS, start=1):
        status.markdown(f"æ­£åœ¨åŠ è½½ï¼š`{ticker}`ï¼ˆ{i}/{total}ï¼‰")
        res = fetch_ticker_data(ticker)
        if isinstance(res, pd.DataFrame) and not res.empty:
            all_dfs.append(res)
        progress.progress(int(i * 100 / total))

    status.markdown("")
    progress.progress(100)

    if not all_dfs:
        st.error("æ— æ³•åŠ è½½æ•°æ®ï¼Œè¯·æ£€æŸ¥ç¼“å­˜æ–‡ä»¶å¤¹æˆ– API æƒé™ã€‚")
        st.stop()

    full_df = pd.concat(all_dfs, ignore_index=True)
    required_cols = {"Flow", "Date", "Ticker"}
    missing = required_cols - set(full_df.columns)
    if missing:
        st.error(f"æ•°æ®åˆ—ç¼ºå¤±ï¼š{sorted(missing)}ã€‚è¯·åˆ é™¤ `tiingo_ticker_cache` ä¸‹æ—§ç¼“å­˜åé‡è¯•ã€‚")
        st.stop()

    full_df["æ¿å—"] = full_df["Ticker"].map(TICKER_TO_SECTOR)

    flow_mean = full_df["Flow"].mean()
    flow_std = full_df["Flow"].std()
    if not np.isfinite(flow_std) or flow_std == 0:
        flow_std = 1e-9

    full_df["Intensity"] = (full_df["Flow"] - flow_mean) / flow_std

    # ä¾§è¾¹æ ï¼šé¢‘ç‡åˆ‡æ¢ï¼ˆå¤©/å‘¨/æœˆï¼‰
    freq = st.sidebar.radio("ç»Ÿè®¡é¢‘ç‡", ["å¤©", "å‘¨", "æœˆ"], index=0, horizontal=True)

    # ç»Ÿä¸€æ—¥æœŸåˆ—ä¸º datetimeï¼Œä¾¿äºæŒ‰å‘¨/æœˆèšåˆ
    full_df["Date"] = pd.to_datetime(full_df["Date"], errors="coerce")
    full_df = full_df.dropna(subset=["æ¿å—", "Date"])

    if freq == "å‘¨":
        # ç”¨æ¯å‘¨å‘¨ä¸€ä½œä¸ºâ€œå‘¨â€æ ‡ç­¾ï¼ˆå‘¨é¢‘èšåˆï¼‰
        full_df["æ—¥æœŸ"] = full_df["Date"].dt.to_period("W-MON").dt.start_time.dt.strftime("%Y-%m-%d")
        recent_units_label = "æ˜¾ç¤ºæœ€è¿‘å‘¨æ•°"
    elif freq == "æœˆ":
        # ç”¨æ¯æœˆæœˆåˆä½œä¸ºâ€œæœˆâ€æ ‡ç­¾ï¼ˆæœˆé¢‘èšåˆï¼‰
        full_df["æ—¥æœŸ"] = full_df["Date"].dt.to_period("M").dt.start_time.dt.strftime("%Y-%m-%d")
        recent_units_label = "æ˜¾ç¤ºæœ€è¿‘æœˆæ•°"
    else:
        full_df["æ—¥æœŸ"] = full_df["Date"].dt.strftime("%Y-%m-%d")
        recent_units_label = "æ˜¾ç¤ºæœ€è¿‘äº¤æ˜“æ—¥æ•°"

    pivot = (
        full_df.pivot_table(index=["æ¿å—", "Ticker"], columns="æ—¥æœŸ", values="Intensity", aggfunc="mean")
        .fillna(0)
    )

    # åˆ—æŒ‰å€’åºï¼ˆæœ€è¿‘åœ¨å·¦ï¼‰
    pivot = pivot.reindex(sorted(pivot.columns, reverse=True), axis=1)

    # æœ€è¿‘ N ä¸ªå‘¨æœŸï¼ˆå¤©/å‘¨/æœˆï¼‰
    recent_units = st.sidebar.slider(recent_units_label, 5, 30, 15)
    if pivot.shape[1] > recent_units:
        pivot = pivot.iloc[:, :recent_units]
    st.sidebar.markdown(
        r"""
    ### ğŸ“– äº¤äº’æŒ‡å—ï¼š
    1\. \*\*æŠ˜å æŸ¥çœ‹æ¦‚å†µ\*\*ï¼šå·¦ä¾§â€œæ¿å—/ETFâ€åˆ—å¯æŠ˜å /å±•å¼€åˆ†ç»„ã€‚  

    2\. \*\*å±•å¼€çœ‹ç»†åˆ†\*\*ï¼šæ¯ä¸ªæ¿å—ä¸‹å±•ç¤ºå¯¹åº” ETF æ˜ç»†ã€‚  

    3\. \*\*é¢œè‰²è§£è¯»\*\*ï¼šæœ¬é¡µâ€œèµ„é‡‘æµå¼ºåº¦â€æ¥è‡ª CLV\+æˆäº¤é¢çš„é‡åŒ–è®¡ç®—ï¼Œå¹¶åšæ ‡å‡†åŒ–åç€è‰²ã€‚  
       - \*\*èµ„é‡‘æµï¼ˆFlowï¼‰è®¡ç®—\*\*ï¼šå…ˆè®¡ç®— CLVï¼ˆClose Location Valueï¼Œæ”¶ç›˜ä»·åœ¨å½“æ—¥åŒºé—´çš„ä½ç½®ï¼‰  
         $$CLV=\frac{(C-L)-(H-C)}{H-L}=\frac{2C-H-L}{H-L}$$
         å…¶ä¸­ $C=adjClose$ã€$H=adjHigh$ã€$L=adjLow$ã€‚ä¸ºé¿å… $H=L$ çš„é™¤é›¶ï¼Œä»£ç ç”¨ $H-L+1e-9$ åšå¹³æ»‘ã€‚  
         ç„¶åç”¨â€œCLV \* ä»·æ ¼ \* æˆäº¤é‡â€è¿‘ä¼¼å½“æ—¥èµ„é‡‘æµå¼ºå¼±ï¼š  
         $$Flow=CLV\times(adjClose\times volume)$$
       - \*\*å¼ºåº¦ï¼ˆIntensityï¼‰è®¡ç®—\*\*ï¼šå¯¹å…¨æ ·æœ¬çš„ Flow åš Z\-score æ ‡å‡†åŒ–ï¼š  
         $$Intensity=\frac{Flow-mean(Flow)}{std(Flow)}$$
         è‹¥æ ‡å‡†å·®ä¸º 0ï¼ˆæˆ–éæœ‰é™å€¼ï¼‰åˆ™ç”¨æå°å€¼æ›¿ä»£ä»¥é¿å…é™¤é›¶ã€‚  
       - \*\*èšåˆä¸é¢œè‰²\*\*ï¼šæŒ‰â€œå¤©/å‘¨/æœˆâ€å¯¹ Intensity å–å‡å€¼èšåˆã€‚Intensity \> 0 æ˜¾ç¤ºçº¢è‰²ï¼Œ\< 0 æ˜¾ç¤ºç»¿è‰²ï¼›é¢œè‰²è¶Šæ·±è¡¨ç¤º $|Intensity|$ è¶Šå¤§ï¼ˆè¶Šâ€œå¼ºâ€ï¼‰ã€‚
    """,
        unsafe_allow_html=True,
    )
    # --- 4. ä½¿ç”¨ AgGrid æ¸²æŸ“ï¼ˆåˆ†ç»„æŠ˜å  + çƒ­åŠ›ï¼‰ ---
    grid_df = pivot.reset_index()

    cellstyle_jscode = JsCode(
        """
        function(params) {
            const v = params.value;
            if (v === null || v === undefined) return {};
            const x = Number(v);
            if (isNaN(x)) return {};

            const scale = 1.6;
            const minAlpha = 0.20;
            const maxAlpha = 0.95;

            let a = Math.min(Math.abs(x) / scale, 1.0);
            a = minAlpha + (maxAlpha - minAlpha) * a;

            const textColor = (a >= 0.60) ? "white" : "black";

            if (x > 0) {
                return { backgroundColor: `rgba(255,0,0,${a})`, color: textColor };
            } else if (x < 0) {
                return { backgroundColor: `rgba(0,160,0,${a})`, color: textColor };
            } else {
                return { backgroundColor: "white", color: "black" };
            }
        }
        """
    )

    # ä¸ä½¿ç”¨ HTMLï¼Œç›´æ¥æ‹¼æ¥çº¯æ–‡æœ¬ï¼šä¸­æ–‡å (Ticker)
    def _format_name(row: pd.Series) -> str:
        t = str(row["Ticker"])
        cn = CHINESE_NAMES.get(t, t)
        return f"{t}-{cn}"

    grid_df["åç§°"] = grid_df.apply(_format_name, axis=1)

    # --- é…ç½® AgGridï¼šç”¨â€œåç§°â€æ›¿ä»£åŸæ¥å·¦ä¾§çš„ Ticker åˆ—å±•ç¤º ---
    gb = GridOptionsBuilder.from_dataframe(grid_df)

    gb.configure_column("æ¿å—", rowGroup=True, hide=True)
    gb.configure_column("Ticker", hide=True)

    gb.configure_column(
        "åç§°",
        header_name="Ticker",
        pinned="left",
        width=260,
        minWidth=200,
        maxWidth=420,
    )

    date_cols = [c for c in grid_df.columns if c not in ("æ¿å—", "Ticker", "åç§°")]
    default_sort_col = date_cols[0] if date_cols else None

    for c in date_cols:
        gb.configure_column(
            c,
            headerName=str(c),
            type=["numericColumn"],
            aggFunc="avg",
            suppressAggFuncInHeader=True,
            valueFormatter="(params.value==null)?'':Number(params.value).toFixed(2)",
            cellStyle=cellstyle_jscode,
            suppressSizeToFit=True,
            sort="desc" if c == default_sort_col else None,  # \u2190 æ–°å¢ï¼šé»˜è®¤æŒ‰æœ€æ–°åˆ—å€’åº
        )
    gb.configure_default_column(sortable=True, filter=True, resizable=True)

    if "_ag_grid_ver" not in st.session_state:
        st.session_state["_ag_grid_ver"] = 0

    c1, c2, c3 = st.columns([1, 1, 8])
    with c1:
        if st.button("å±•å¼€æ‰€æœ‰", use_container_width=True):
            st.session_state["_ag_expand_mode"] = "expand"
            st.session_state["_ag_grid_ver"] += 1
    with c2:
        if st.button("æŠ˜å æ‰€æœ‰", use_container_width=True):
            st.session_state["_ag_expand_mode"] = "collapse"
            st.session_state["_ag_grid_ver"] += 1

    expand_mode = st.session_state.get("_ag_expand_mode", "expand")  # "expand" / "collapse"

    on_grid_ready = JsCode(
        f"""
        function(params) {{
            try {{
                const mode = {repr(expand_mode)};

                if (mode) {{
                    params.api.forEachNode(function(node) {{
                        if (node.group) {{
                            node.setExpanded(mode === "expand");
                        }}
                    }});
                }}

                setTimeout(function () {{
                    try {{
                        const allColIds = [];
                        params.columnApi.getAllColumns().forEach(function (col) {{
                            allColIds.push(col.getColId());
                        }});
                        params.columnApi.autoSizeColumns(allColIds, false);
                    }} catch (e) {{}}
                }}, 50);
            }} catch (e) {{}}
        }}
        """
    )
    gb.configure_grid_options(
        groupDisplayType="singleColumn",
        groupIncludeFooter=True,
        groupIncludeTotalFooter=True,
        autoGroupColumnDef={
            "headerName": "æ¿å—/ETF",
            "minWidth": 130,
            "pinned": "left",
            "cellRendererParams": {"suppressCount": False},
        },
        domLayout="normal",
        rowHeight=32,
        onGridReady=on_grid_ready,
    )

    grid_options = gb.build()

    AgGrid(
        grid_df,
        gridOptions=grid_options,
        height=1500,
        allow_unsafe_jscode=True,
        enable_enterprise_modules=True,
        theme="streamlit",
        fit_columns_on_grid_load=False,
        key=f"market_intensity_grid_{st.session_state['_ag_grid_ver']}",
    )

    # --- æ‰§è¡Œåæ¸…é™¤è§¦å‘æ ‡è®°ï¼Œé¿å…ä¸‹æ¬¡é‡å»ºé‡å¤åŠ¨ä½œ ---
    if "_ag_expand_mode" in st.session_state:
        del st.session_state["_ag_expand_mode"]
