import streamlit as st
import pandas as pd
import yfinance as yf
import talib
import numpy as np
import json
import os
import io
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import TypedDict, Dict, List, Optional, Any
from langgraph.graph import StateGraph, START, END
from google import genai
from dotenv import load_dotenv
from urllib.request import Request, urlopen
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# --- 1. ç»“æ„åŒ–æ•°æ®å®šä¹‰ ---
class SentimentResult(BaseModel):
    score: float = Field(description="æƒ…ç»ªåˆ†æ•°ï¼ŒèŒƒå›´ä» -1.0 (åˆ©ç©º) åˆ° 1.0 (åˆ©å¥½)")
    reason: str = Field(description="ç®€çŸ­åˆ†æç†ç”±ï¼Œé™ 20 å­—")


class BatchSentiment(BaseModel):
    results: Dict[str, SentimentResult] = Field(description="ä»¥ Ticker ä¸ºé”®ï¼ŒSentimentResult ä¸ºå€¼çš„å­—å…¸")


class GraphState(TypedDict):
    dynamic_etf_list: List[str]
    etf_news_sentiment: Dict[str, int]
    etf_news_reasons: Dict[str, str]
    etf_highlights: Optional[pd.DataFrame]
    raw_sectors: Optional[pd.DataFrame]
    raw_industries: Optional[pd.DataFrame]
    hierarchy_db: Any
    etf_cn_map: Dict[str, str]  # âœ… æ–°å¢ï¼šETF ticker -> ä¸­æ–‡å
    error: Optional[str]



# --- 2. æ ¸å¿ƒè¾…åŠ©å‡½æ•° ---
def get_rss_news(ticker: str) -> List[str]:
    """è·å–æ ‡çš„è¿‘ 7 å¤©å®æ—¶æ–°é—»æ ‡é¢˜"""
    try:
        url = f"https://news.google.com/rss/search?q={ticker}+stock+when:7d&hl=en-US&gl=US&ceid=US:en"
        headers = {'User-Agent': 'Mozilla/5.0'}
        req = Request(url, headers=headers)
        with urlopen(req, timeout=10) as response:
            root = ET.fromstring(response.read())
            return [t.text for item in root.findall('.//item')[:5] if (t := item.find('title')) is not None]
    except:
        return []


# --- 3. èŠ‚ç‚¹é€»è¾‘ ---

def discover_etf_node(state: GraphState):
    """èŠ‚ç‚¹ 1: æ‰«ææœ€æ´»è·ƒ ETF åˆ—è¡¨"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    url = "https://finviz.com/screener.ashx?v=111&f=ind_exchangetradedfund&o=-volume"
    try:
        req = Request(url, headers=headers)
        with urlopen(req, timeout=15) as resp:
            df = pd.read_html(io.StringIO(resp.read().decode('utf-8')))[-2]
            return {"dynamic_etf_list": df['Ticker'].tolist()[:25]}
    except:
        return {"dynamic_etf_list": ['SPY', 'QQQ', 'IWM', 'SMH', 'XLK']}


def sentiment_node(state: GraphState):
    """èŠ‚ç‚¹ 2: AI å®æ—¶èˆ†æƒ…è¯„åˆ† (40% æƒé‡)"""
    etf_pool = state.get("dynamic_etf_list", [])
    client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
    parser = JsonOutputParser(pydantic_object=BatchSentiment)

    sentiment_map, reason_map = {}, {}
    status_placeholder = st.empty()

    # åˆ†æ‰¹å¤„ç†æé«˜ç¨³å®šæ€§
    for i in range(0, min(len(etf_pool), 12), 4):
        batch = etf_pool[i:i + 4]
        status_placeholder.text(f"ğŸ§ª AI æ·±åº¦è§£æèˆ†æƒ…ä¸­: {batch}...")
        news_payload = [{"ticker": t, "news": get_rss_news(t)} for t in batch]

        prompt = f"åˆ†ææ ‡çš„æœ€æ–°æƒ…ç»ªï¼š\n{parser.get_format_instructions()}\næ•°æ®ï¼š{json.dumps(news_payload)}"
        try:
            response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt,
                                                      config={'response_mime_type': 'application/json'})
            parsed = parser.parse(response.text)
            for t, res in parsed['results'].items():
                sentiment_map[t] = int((float(res['score']) + 1) * 50)
                reason_map[t] = res['reason']
        except:
            continue
    status_placeholder.empty()
    return {"etf_news_sentiment": sentiment_map, "etf_news_reasons": reason_map}


def etf_scanner_node(state: GraphState):
    """èŠ‚ç‚¹ 3: TA-Lib é‡ä»·æŒ‡æ ‡ + AI æƒ…ç»ªèåˆ (60:40)"""
    etf_pool = state.get("dynamic_etf_list", [])
    sent_scores = state.get("etf_news_sentiment", {})
    sent_reasons = state.get("etf_news_reasons", {})
    results = []

    for ticker in etf_pool:
        try:
            df = yf.download(ticker, start=datetime.now() - timedelta(days=60), progress=False)
            if df is None or len(df) < 20: continue

            # å¤„ç† MultiIndex ç¡®ä¿å–å‡ºä¸€ç»´æ•°ç»„
            closes = df['Close'].iloc[:, 0].values if isinstance(df['Close'], pd.DataFrame) else df['Close'].values
            volumes = df['Volume'].iloc[:, 0].values if isinstance(df['Volume'], pd.DataFrame) else df['Volume'].values
            closes, volumes = closes.flatten().astype(float), volumes.flatten().astype(float)

            # æŠ€æœ¯é¢åˆ†ï¼šåŸºäº OBV æ–œç‡ä¸ä»·æ ¼é«˜ä½
            obv = talib.OBV(closes, volumes)
            slope = talib.LINEARREG_SLOPE(obv, timeperiod=5)[-1]
            tech_score = int((closes[-1] / np.max(closes[-20:])) * 75 + (15 if slope > 0 else 0))

            # èˆ†æƒ…åˆ†ï¼šè·å– AI è¯„åˆ†
            news_score = sent_scores.get(ticker, 50)

            # ç»¼åˆå¼ºåº¦
            comp_score = int(tech_score * 0.6 + news_score * 0.4)

            # å¤šå¤´å†³ç­–å»ºè®®
            if comp_score >= 82 and slope > 0:
                rec, reason = "ğŸŒŸ å¼ºçƒˆæ¨è", "é‡ä»·èˆ†æƒ…å¼ºåŠ›å…±æŒ¯"
            elif tech_score >= 75 and slope > 0:
                rec, reason = "âœ… å»ºè®®ä¹°å…¥", "æŠ€æœ¯è¶‹åŠ¿å¤šå¤´å ä¼˜"
            elif news_score >= 80 and slope <= 0:
                rec, reason = "âš ï¸ è­¦æƒ•è¯±å¤š", "æƒ…ç»ªäº¢å¥‹ä½†èµ„é‡‘é¢èƒŒç¦»"
            else:
                rec, reason = "âŒ æš‚ä¸æ¨è", "åˆåŠ›ä¸è¶³æˆ–è¶‹åŠ¿åå¼±"

            results.append({
                "ä»£ç ": ticker, "ç°ä»·": f"${closes[-1]:.2f}",
                "æŠ€æœ¯åˆ†": tech_score, "èˆ†æƒ…åˆ†": news_score, "ç»¼åˆå¼ºåº¦": comp_score,
                "å†³ç­–å»ºè®®": rec, "å¤šå¤´ç†ç”±": reason, "AIè§£è¯»": sent_reasons.get(ticker, "æ— ")
            })
        except:
            continue
    return {"etf_highlights": pd.DataFrame(results).sort_values("ç»¼åˆå¼ºåº¦", ascending=False)}


def fetch_market_node(state: GraphState):
    """èŠ‚ç‚¹ 4: æ¿å—è¡Œæƒ…åŸå§‹æ•°æ®"""
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        def get_data(g):
            url = f"https://finviz.com/groups.ashx?g={g}&v=140&o=-perf1m"
            req = Request(url, headers=headers)
            with urlopen(req, timeout=15) as resp:
                df = pd.read_html(io.StringIO(resp.read().decode('utf-8')))[-2]
                for col in ['Perf Week', 'Perf Month']:
                    df[col] = df[col].astype(str).str.replace('%', '').replace('-', '0').astype(float)
                return df

        return {"raw_sectors": get_data('sector'), "raw_industries": get_data('industry')}
    except:
        return {"error": "æ¿å—æŠ“å–å¤±è´¥"}


def ai_modeling_node(state: GraphState):
    """èŠ‚ç‚¹ 5: AI è‡ªåŠ¨åŒ–å±‚çº§æ ‘å»ºæ¨¡ + ETF ä¸­æ–‡åæ˜ å°„"""
    client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

    sectors = state["raw_sectors"]["Name"].tolist() if state.get("raw_sectors") is not None else []
    industries = state["raw_industries"]["Name"].tolist() if state.get("raw_industries") is not None else []
    etfs = state.get("dynamic_etf_list", [])[:25]

    # è¦æ±‚æ¨¡å‹è¿”å›å›ºå®šç»“æ„ï¼šmarket_hierarchy + etf_cn_map
    prompt = (
        "è¯·è¾“å‡º JSONï¼ŒåŒ…å«ä¸¤ä¸ªå­—æ®µï¼š\n"
        "1) market_hierarchy: ä»¥ Sector è‹±æ–‡åä¸º keyï¼Œvalue åŒ…å« cn(ä¸­æ–‡å) ä¸ sub(å­è¡Œä¸šæ•°ç»„)ï¼Œ"
        "sub å…ƒç´ åŒ…å« en/cn/descã€‚\n"
        "2) etf_cn_map: ä»¥ ETF ticker ä¸º keyï¼Œvalue ä¸ºä¸­æ–‡åï¼ˆæ— æ³•ç¡®å®šåˆ™ç»™å‡ºç®€çŸ­ä¸­æ–‡æˆ–åŸ tickerï¼‰ã€‚\n"
        f"Sectors: {sectors}\n"
        f"Industries: {industries}\n"
        f"ETFs: {etfs}\n"
    )

    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
            config={"response_mime_type": "application/json"},
        )
        h_data = json.loads(response.text) if response and getattr(response, "text", None) else {}

        # å…œåº•è§„èŒƒåŒ–
        market_h = h_data.get("market_hierarchy") if isinstance(h_data, dict) else {}
        etf_cn_map = h_data.get("etf_cn_map") if isinstance(h_data, dict) else {}

        if not isinstance(market_h, dict):
            market_h = {}
        if not isinstance(etf_cn_map, dict):
            etf_cn_map = {}

        payload = {"market_hierarchy": market_h, "etf_cn_map": etf_cn_map}
        with open("market_hierarchy.json", "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=4)

        return {"hierarchy_db": market_h, "etf_cn_map": etf_cn_map}
    except:
        return {}


# --- 4. æ„å»ºå·¥ä½œæµ ---
def build_workflow():
    workflow = StateGraph(GraphState)
    workflow.add_node("discover", discover_etf_node)
    workflow.add_node("sentiment", sentiment_node)
    workflow.add_node("scanner", etf_scanner_node)
    workflow.add_node("fetcher", fetch_market_node)
    workflow.add_node("ai", ai_modeling_node)

    workflow.add_edge(START, "discover")
    workflow.add_edge("discover", "sentiment")
    workflow.add_edge("sentiment", "scanner")
    workflow.add_edge("scanner", "fetcher")
    workflow.add_edge("fetcher", "ai")
    workflow.add_edge("ai", END)
    return workflow.compile()


# --- 5. æ¸²æŸ“ UI ---

def render_ui():
    st.set_page_config(page_title="AI é‡åŒ–å†³ç­–ç³»ç»Ÿ", layout="wide")
    st.title("ğŸ¦… æ™ºèƒ½å¤šå¤´é‡åŒ–ä¸è¡Œä¸šè§£æçœ‹æ¿")

    if st.button("ğŸš€ å¯åŠ¨å…¨æµç¨‹æ·±åº¦æ‰«æ", type="primary"):
        app = build_workflow()
        current_state = {
            "dynamic_etf_list": [],
            "etf_news_sentiment": {},
            "etf_news_reasons": {},
            "etf_highlights": pd.DataFrame(),
            "raw_sectors": None,
            "raw_industries": None,
            "hierarchy_db": {},
            "etf_cn_map": {},  # âœ… æ–°å¢
            "error": None,
        }
        with st.status("æ­£åœ¨è¿›è¡Œå¤šç»´äº¤å‰åˆ†æ...", expanded=True) as status:
            for event in app.stream(current_state):
                for node_name, output in event.items():
                    st.write(f"âœ… èŠ‚ç‚¹ `{node_name}` å¤„ç†å®Œæ¯•")
                    if output:
                        current_state.update(output)
            status.update(label="æ‰«æå®Œæ¯•!", state="complete")
        st.session_state.final_state = current_state

    if "final_state" in st.session_state:
        state = st.session_state.final_state

        # --- ETF ä¸­æ–‡åæ˜ å°„ï¼ˆç”¨äºä¸»è¡¨ + è¡Œä¸šé€è§†æ ‘å±•ç¤ºï¼‰ ---
        etf_cn_map = state.get("etf_cn_map") or {}
        if not isinstance(etf_cn_map, dict):
            etf_cn_map = {}

        # 1. å¤šå¤´å†³ç­–ä¸»è¡¨ï¼šå¢åŠ ã€Œä¸­æ–‡åã€åˆ—
        if state.get("etf_highlights") is not None and not state["etf_highlights"].empty:
            st.subheader("ğŸ”¥ å®æ—¶é‡åŒ–ä¸èˆ†æƒ…å…±æŒ¯æ¦œå•")
            df_show = state["etf_highlights"].copy()
            if "ä»£ç " in df_show.columns:
                df_show.insert(0, "ä¸­æ–‡å", df_show["ä»£ç "].map(lambda x: etf_cn_map.get(str(x), str(x))))

            st.dataframe(
                df_show,
                width="stretch",
                hide_index=True,
                column_config={
                    "ç»¼åˆå¼ºåº¦": st.column_config.ProgressColumn(min_value=0, max_value=100),
                    "å¤šå¤´ç†ç”±": st.column_config.TextColumn(width="large"),
                },
            )

        # 2. è¡Œä¸šé€è§†æ ‘ï¼šåœ¨æ ‡é¢˜å¤„å±•ç¤º ETF ä¸­æ–‡ååˆ—è¡¨ï¼ˆæ¥è‡ªåŠ¨æ€ ETF æ± ï¼‰
        if state.get("raw_sectors") is not None:
            st.divider()
            st.subheader("ğŸŒ³ è¡Œä¸šé€è§†å±‚çº§æ ‘ (AI å½’ç±»)")

            # å±•ç¤º ETF ä¸­æ–‡åæ¦‚è§ˆï¼ˆæ”¾åœ¨è¡Œä¸šæ ‘ä¸Šæ–¹ï¼‰
            etf_pool = state.get("dynamic_etf_list", [])[:25]
            if etf_pool:
                cn_list = [etf_cn_map.get(t, t) for t in etf_pool]
                st.caption("æœ¬æ¬¡æ‰«æ ETF: " + " / ".join(cn_list))

            s_df, i_df = state["raw_sectors"], state["raw_industries"]

            # å…³é”®ä¿®å¤ï¼šæŠŠ hierarchy_db è§„èŒƒåŒ–ä¸º dictï¼Œé¿å… list.get æŠ¥é”™
            h_db = state.get("hierarchy_db") or {}
            if isinstance(h_db, list):
                h_db = h_db[0] if (len(h_db) > 0 and isinstance(h_db[0], dict)) else {}
            elif not isinstance(h_db, dict):
                h_db = {}

            for _, s_row in s_df.sort_values("Perf Month", ascending=False).iterrows():
                s_en = s_row["Name"]
                s_meta = h_db.get(s_en, {"cn": s_en, "sub": []})
                icon = "ğŸ”´" if s_row["Perf Month"] > 0 else "ğŸŸ¢"

                with st.expander(f"{icon} {s_row['Perf Month']}% | {s_meta.get('cn', s_en)}"):
                    sub_list = s_meta.get("sub", [])
                    sub_names = [item.get("en") for item in sub_list if isinstance(item, dict)]
                    sub_data = i_df[i_df["Name"].isin(sub_names)].copy()

                    if not sub_data.empty:
                        map_dict = {
                            item["en"]: (item.get("cn", item["en"]), item.get("desc", ""))
                            for item in sub_list
                            if isinstance(item, dict) and "en" in item
                        }
                        sub_data["ä¸­æ–‡å"] = sub_data["Name"].apply(lambda x: map_dict.get(x, (x, ""))[0])
                        sub_data["æœˆæ¶¨å¹…%"] = sub_data["Perf Month"]
                        st.dataframe(
                            sub_data[["ä¸­æ–‡å", "Name", "æœˆæ¶¨å¹…%"]].rename(columns={"Name": "åŸå"}).style.map(
                                lambda x: (
                                    "color: #ff4b4b; font-weight: bold"
                                    if isinstance(x, float) and x > 0
                                    else "color: #09ab3b; font-weight: bold"
                                    if isinstance(x, float) and x < 0
                                    else ""
                                ),
                                subset=["æœˆæ¶¨å¹…%"],
                            ),
                            width="stretch",
                            hide_index=True,
                        )
if __name__ == "__main__":
    render_ui()
