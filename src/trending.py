import streamlit as st
import yfinance as yf
import pandas as pd
import plotly.graph_objects as go
import os
import re
from google import genai
from google.genai import types
import logging
import contextlib
from contextlib import nullcontext

# Reduce noisy log output from yfinance / urllib3
logging.getLogger('yfinance').setLevel(logging.ERROR)
logging.getLogger('urllib3').setLevel(logging.WARNING)


# Helper to suppress noisy yfinance stdout/stderr (prevents 'Failed download' lines flooding the UI/console)
def safe_yf_download(*args, **kwargs):
    devnull = open(os.devnull, 'w')
    try:
        with contextlib.redirect_stdout(devnull), contextlib.redirect_stderr(devnull):
            return yf.download(*args, **kwargs)
    finally:
        devnull.close()


def sanitize_and_validate_user_tickers(raw_input, max_keep=50):
    """Parse and validate user-provided tickers. Returns (valid_list, invalid_list).

    Uses a conservative regex + a short yf check to ensure the symbol exists before proceeding.
    """
    if not raw_input or not raw_input.strip():
        return [], []

    tokens = re.split(r'[,\s]+', raw_input.strip())
    seen = set()
    valid = []
    invalid = []

    for tok in tokens:
        if not tok:
            continue
        t = tok.strip().upper().lstrip('$').strip(',')
        t = t.replace('.', '-')  # normalize BRK.B -> BRK-B
        if not re.match(r'^[A-Z][A-Z0-9\-]{0,5}$', t):
            invalid.append(tok)
            continue
        if t in seen:
            continue
        seen.add(t)
        # quick existence check
        try:
            df = safe_yf_download(t, period='5d', interval='1d', progress=False, auto_adjust=True)
            if df is not None and not df.empty:
                valid.append(t)
            else:
                invalid.append(tok)
        except Exception:
            invalid.append(tok)
        if len(valid) >= max_keep:
            break

    return valid, invalid


# --- 1. ç¯å¢ƒä¸è¿æ¥é…ç½® ---

gemini_api_key = os.getenv("GEMINI_API_KEY")
if not gemini_api_key:
    raise ValueError("Environment variable GEMINI_API_KEY is not set or is empty.")

client = genai.Client(api_key=gemini_api_key)


# --- 2. æ ¸å¿ƒé‡åŒ–ç®—æ³•åº“ ---
@st.cache_data(ttl=3600)
def get_structured_data(ticker):
    try:
        data = safe_yf_download(ticker, period="1y", interval="1d", auto_adjust=True)
        if data.empty: return None
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.get_level_values(0)

        close = data['Close']
        if isinstance(close, pd.DataFrame):
            close = close.iloc[:, 0]

        ma50 = close.rolling(50).mean()
        ma200 = close.rolling(200).mean()

        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rsi = 100 - (100 / (1 + (gain / loss)))

        curr_p = float(close.iloc[-1])
        curr_m50 = float(ma50.iloc[-1])
        curr_m200 = float(ma200.iloc[-1])
        curr_rsi = float(rsi.iloc[-1])
        bias = (curr_p - curr_m200) / curr_m200

        if curr_p > curr_m200 and curr_m50 < curr_m200:
            phase = "ğŸŸ¢ èµ·æ­¥é˜¶æ®µ"
        elif curr_p > curr_m50 > curr_m200 and bias < 0.25:
            phase = "ğŸ“ˆ ä¸Šå‡é˜¶æ®µ"
        elif curr_p > curr_m50 and bias >= 0.25:
            phase = "ğŸ”¥ æˆç†Ÿé˜¶æ®µ"
        else:
            phase = "ğŸ“‰ è°ƒæ•´é˜¶æ®µ"

        return {"df": data, "price": curr_p, "rsi": curr_rsi, "bias": bias, "phase": phase, "ticker": ticker}
    except Exception as e:
        print(f"[{ticker}] æ•°æ®æŠ“å–å¤±è´¥: {e}")
        return None


# --- 3. å¼€å¯æœç´¢èƒ½åŠ›çš„ AI æ¨¡å— ---

@st.cache_data(ttl=3600)
def get_ai_suggestions() -> str:
    """Ensure the function explicitly returns a string."""
    time_str = pd.Timestamp.now().strftime("%Yå¹´-%mæœˆ-%dæ—¥")
    prompt = f"""
    è¯·åœ¨ç¾è‚¡å¸‚åœºä¸­ç­›é€‰å‡ºå½“å‰ï¼ˆ{time_str}ï¼‰æ—¶é—´æœ€è¿‘ 5 ä¸ªäº¤æ˜“æ—¥å†…æ»¡è¶³ä»¥ä¸‹é‡ä»·ä¸æƒ…ç»ªç‰¹å¾çš„ETFï¼ˆä¸è¦è‚¡ç¥¨ï¼‰ï¼š
    1) æˆäº¤é‡è¿ç»­æ”¾å¤§ï¼ˆè¿ç»­ 3 æ—¥æˆ–ä»¥ä¸Šæˆäº¤é‡ç¯æ¯”ä¸Šå‡ï¼‰
    2) ä»·æ ¼è¿‘æœŸåˆ›è¿‘æœŸé«˜ç‚¹æˆ–å‘ˆç¨³æ­¥æ”€å‡è¶‹åŠ¿
    3) ç¤¾äº¤/æ–°é—»æƒ…ç»ªæ˜æ˜¾ä¸Šå‡ï¼ˆå¦‚æƒ…ç»ªæ•°æ®æˆ–ç¤¾åª’çƒ­åº¦/æåŠåº¦æ˜æ˜¾æé«˜ï¼‰

    è¯·ä¼˜å…ˆæ¶µç›–ä»¥ä¸‹ä¸»é¢˜ï¼š
    - ç§‘æŠ€/AI 
    - åŠ å¯†è´§å¸
    - è´µé‡‘å±ï¼ˆé»„é‡‘/ç™½é“¶ï¼‰
    - èƒ½æº
    - åŠ¨é‡/æƒ…ç»ªå‹
    
    è¾“å‡ºï¼š
    æŒ‰ç…§çƒ­åº¦æ’åç­›é€‰å‡ºæœ€çƒ­çš„5ä¸ªETFä»£ç ï¼Œä»…è¿”å›ä»£ç æˆ–ç¬¦å·ï¼Œç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚ä¾‹å¦‚ï¼šQQQ, NVDA, GLD
    """
    response = client.models.generate_content(
        model='gemini-2.0-flash', contents=prompt
    )
    raw_text = response.text.upper()
    print("raw_text:" + raw_text)
    return raw_text


@st.cache_data(ttl=3600)
def get_ai_summary(ticker, phase, rsi, bias):
    """åŸºäºå®æ—¶æœç´¢çš„æ·±åº¦ç»“æ„åŒ–é¢„æµ‹"""
    search_tool = types.Tool(google_search=types.GoogleSearch())

    # ç³»ç»ŸæŒ‡ä»¤ï¼šå¼ºåˆ¶æ¨¡å‹è¿›è¡Œç»“æ„åŒ–é“¾å¼æ¨ç†
    sys_instruction = "ä½ æ˜¯ä¸€ä¸ªå…¨çƒå®è§‚ç­–ç•¥ä¸“å®¶ã€‚ä½ å¿…é¡»ç»“åˆ Google æœç´¢åˆ°çš„ 2026 å¹´æœ€æ–°å®è§‚æ•°æ®ã€æ”¿ç­–å˜é‡è¿›è¡Œæ¨ç†ã€‚"

    prompt = f"""
    åˆ†æETFï¼š{ticker}ã€‚å½“å‰æŠ€æœ¯æŒ‡æ ‡ï¼šé˜¶æ®µ={phase}, RSI={rsi:.1f}, ä¹–ç¦»ç‡(Bias)={bias:.1%}ã€‚

    ä»»åŠ¡ï¼š
    1. æœç´¢å¹¶ç¡®è®¤è¯¥èµ„äº§è¿‘æœŸçš„æ ¸å¿ƒé©±åŠ¨äº‹ä»¶ï¼ˆå¦‚è´¢æŠ¥ã€åˆ©ç‡å†³è®®ã€åœ°ç¼˜åŠ¨æ€ã€éœ€æ±‚çƒ­åº¦ç­‰ï¼‰ã€‚
    2. åŸºäºâ€œç»“æ„åŒ–ä¼ å¯¼é€»è¾‘â€ï¼šå¦‚æœè¯¥èµ„äº§æŒç»­èµ°å¼º/èµ°å¼±ï¼Œå“ªä¸€ä¸ªå…³è”äº§ä¸šç¯èŠ‚å°†æˆä¸ºä¸‹ä¸€ä¸ªçˆ†å‘ç‚¹ï¼Ÿ
    3. ç»™å‡ºé¢„æµ‹ï¼šè¶‹åŠ¿ â†’ ä¾›åº”é“¾/æµåŠ¨æ€§å˜åŒ– â†’ èµ„äº§å½¢æ€ã€‚
    4. æ¯ä¸ªETFç›´æ¥ç»™å‡º 2 ä¸ªç²¾å‡†çš„ä¼ å¯¼æ–¹å‘å’Œæœ€å¯èƒ½çˆ†å‘çš„èµ„äº§ä»£ç ï¼Œä»¥åŠå¯¹æ¯ä¸ªèµ„äº§çš„20å­—åŸå› è¯´æ˜
    è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼ˆä¸­æ–‡ï¼‰ï¼š
    1) èµ„äº§ä»£ç  - çˆ†å‘åŸå› ç®€è¿°
    2) èµ„äº§ä»£ç  - çˆ†å‘åŸå› ç®€è¿°
    åªè¿”å›ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚
    """
    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=prompt,
            config=types.GenerateContentConfig(
                system_instruction=sys_instruction,
                tools=[search_tool]
            )
        )
        return response.text.strip()
    except Exception as e:
        return f"AI æ¨ç†æš‚æ—¶å—é˜»: {str(e)}"


# --- 4. UI è¾…åŠ©å‡½æ•° ---

def make_sparkline(data_series):
    colors = ['#2ca02c' if data_series.iloc[-1] >= data_series.iloc[0] else '#ff4b4b']
    # Correct color comparison and choose fill color based on the actual color
    primary = colors[0]
    if primary == '#2ca02c':
        fill = 'rgba(44, 160, 44, 0.1)'
    else:
        fill = 'rgba(255, 75, 75, 0.1)'

    fig = go.Figure(data=go.Scatter(
        y=data_series, mode='lines', line=dict(color=primary, width=2),
        fill='tozeroy', fillcolor=fill
    ))
    fig.update_layout(
        showlegend=False, xaxis=dict(visible=False), yaxis=dict(visible=False),
        margin=dict(t=5, b=5, l=0, r=0), height=40,
        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
    )
    return fig


def get_top_stocks_in_etf(etf_ticker):
    """Fetch the top-performing stocks within a given ETF, including English and Chinese ETF names."""
    try:
        # Download ETF holdings data (mocked for demonstration)
        holdings = safe_yf_download(etf_ticker, period='1y', interval='1d', progress=False, auto_adjust=True)
        if holdings.empty:
            return f"No data available for ETF: {etf_ticker}"

        # Analyze holdings to find top-performing stocks
        top_stocks = holdings.sort_values(by='performance_metric', ascending=False).head(5)

        # Map ETF ticker to English and Chinese names
        asset_map = {
            "QQQ": {"english": "Invesco QQQ Trust", "chinese": "çº³æ–¯è¾¾å…‹100æŒ‡æ•°"},
            "SMH": {"english": "VanEck Semiconductor ETF", "chinese": "åŠå¯¼ä½“è¡Œä¸š"},
            "BOTZ": {"english": "Global X Robotics & AI ETF", "chinese": "æœºå™¨äººä¸äººå·¥æ™ºèƒ½"},
            "GLD": {"english": "SPDR Gold Trust", "chinese": "é»„é‡‘ETF"},
            "GDX": {"english": "VanEck Gold Miners ETF", "chinese": "é»„é‡‘çŸ¿ä¸šETF"},
            # Add more mappings as needed
        }

        etf_name = asset_map.get(etf_ticker, {"english": "Unknown", "chinese": "æœªçŸ¥"})

        # Add ETF names to the result
        top_stocks["ETF_English_Name"] = etf_name["english"]
        top_stocks["ETF_Chinese_Name"] = etf_name["chinese"]

        return top_stocks[["ticker", "performance_metric", "ETF_English_Name", "ETF_Chinese_Name"]]
    except Exception as e:
        return f"Error fetching data for ETF {etf_ticker}: {str(e)}"


# --- 5. Streamlit é¡µé¢æ„å»º ---
st.set_page_config(page_title="US Asset Structural Trends 2026", layout="wide")

st.title("ğŸ›¡ï¸ æ ¸å¿ƒèµ„äº§ç»“æ„åŒ–è¶‹åŠ¿çœ‹æ¿ (AI æœç´¢å¢å¼ºç‰ˆ)")

# åˆå§‹åŒ– Ticker åˆ—è¡¨
if 'user_tickers' not in st.session_state:
    st.session_state.user_tickers = "IBIT, QQQ, GLD, SLV, SMH"


def auto_detect_market():
    """Ensure compatibility with st.spinner by using a fallback context manager."""
    context = st.spinner("AI æ­£åœ¨å…¨ç½‘æœç´¢æœ€æ–°å™äº‹ç„¦ç‚¹...") if hasattr(st, 'spinner') else nullcontext()
    with context:
        suggestions = get_ai_suggestions()
        if suggestions:
            st.session_state.user_tickers = suggestions
        else:
            st.warning("AI æœç´¢æœªè¿”å›ç»“æœï¼Œè¯·ç¨åé‡è¯•ã€‚")


with st.sidebar:
    st.header("âš™ï¸ åŠ¨æ€èµ„äº§é…ç½®")
    st.button("ğŸ¤– AI æ‰«æä»Šæ—¥å…¨çƒçƒ­ç‚¹", on_click=auto_detect_market)
    ticker_input = st.text_area("æ ‡çš„åˆ—è¡¨ (é€—å·åˆ†éš”)", key="user_tickers", height=100)

tickers = [t.strip().upper() for t in ticker_input.split(",") if t.strip()]

# æ•°æ®å‡†å¤‡é€»è¾‘
asset_map = {"IBIT": "æ¯”ç‰¹å¸ç°è´§", "QQQ": "çº³æŒ‡100", "GLD": "é»„é‡‘ç°è´§", "SLV": "ç™½é“¶ç°è´§", "SMH": "åŠå¯¼ä½“"}

# Adding a column to display the Chinese name of each ETF
# Assuming we have a dictionary mapping ETF codes to their Chinese names
ETF_CHINESE_NAMES = {
    "QQQ": "çº³æ–¯è¾¾å…‹100æŒ‡æ•°",
    "NVDA": "è‹±ä¼Ÿè¾¾",
    "SMCI": "è¶…çº§å¾®ç”µè„‘",
    "IBIT": "æ¯”ç‰¹å¸æœŸè´§",
    "GLD": "é»„é‡‘ETF",
    "GDX": "é»„é‡‘çŸ¿ä¸šETF",
    "XOM": "åŸƒå…‹æ£®ç¾å­š",
    "ARKK": "æ–¹èˆŸåˆ›æ–°ETF"
}

# UI æ¸²æŸ“å±‚
table_data = []
progress_text = "æ­£åœ¨æ‰§è¡Œç»“æ„åŒ–é‡åŒ–æ‰«æ..."
my_bar = st.progress(0, text=progress_text)

# Validate user input before processing
valid_tickers, invalid_tickers = sanitize_and_validate_user_tickers(st.session_state.user_tickers)
if invalid_tickers:
    st.warning(f"ä»¥ä¸‹æ ‡çš„æ— æ•ˆæˆ–æ•°æ®è·å–å¤±è´¥ï¼Œå°†è¢«å¿½ç•¥ï¼š{', '.join(invalid_tickers)}")

for idx, ticker in enumerate(valid_tickers):
    res = get_structured_data(ticker)
    if res:
        ai_pred = get_ai_summary(ticker, res['phase'], res['rsi'], res['bias'])
        table_data.append({**res, "ai_pred": ai_pred, "name": asset_map.get(ticker, ticker),
                           "chinese_name": ETF_CHINESE_NAMES.get(ticker, "æœªçŸ¥æ ‡çš„")})
    my_bar.progress((idx + 1) / len(valid_tickers), text=progress_text)
my_bar.empty()

# --- æ¸²æŸ“è¡¨æ ¼ ---
if table_data:

    st.markdown("---")
    header_cols = st.columns([0.6, 0.8, 1.2, 0.6, 1.2, 1.5, 3])

    labels = ["ä»£ç ", "èµ„äº§", "å½“å‰é˜¶æ®µ", "RSI", "ç»“æ„åŒ–ä¹–ç¦»åº¦", "12Mè¶‹åŠ¿", "ğŸ”® AI å®æ—¶é“¾å¼é¢„æµ‹"]

    # æ˜ç¡®è§£é‡Šæ¯ä¸€åˆ—æ•°å­—/å«ä¹‰ï¼Œä½¿ç”¨ caption åœ¨æ ‡é¢˜ä¸‹æ–¹å±•ç¤ºè¯´æ˜
    header_explanations = [
        "æ ‡çš„ä»£ç ï¼ˆTickerï¼‰ï¼Œæ”¯æŒ ETF æˆ– å•åªè‚¡ç¥¨ï¼Œä¾‹å¦‚ QQQã€NVDA",
        "åº•å±‚èµ„äº§æˆ–ä¸»é¢˜çš„ç®€çŸ­è¯´æ˜ï¼Œä¾‹å¦‚ï¼šçº³æŒ‡100 / è‹±ä¼Ÿè¾¾ / é»„é‡‘",
        "å½“å‰é˜¶æ®µï¼šæ ‡çš„çš„æŠ€æœ¯åˆ†æé˜¶æ®µï¼Œä¾‹å¦‚ï¼šä¸Šæ¶¨é˜¶æ®µã€æˆç†Ÿé˜¶æ®µ",
        "RSIï¼šç›¸å¯¹å¼ºå¼±æŒ‡æ•°ï¼Œè¡¡é‡æ ‡çš„çš„è¶…ä¹°æˆ–è¶…å–çŠ¶æ€",
        "ç»“æ„åŒ–ä¹–ç¦»åº¦ï¼šæ ‡çš„ä»·æ ¼ä¸å…¶å‡å€¼çš„åç¦»ç¨‹åº¦ï¼Œæ˜¾ç¤ºä¸ºç™¾åˆ†æ¯”",
        "12Mè¶‹åŠ¿ï¼šæ ‡çš„æœ€è¿‘ä¸€å¹´çš„ä»·æ ¼è¶‹åŠ¿å›¾",
        "ğŸ”® AI å®æ—¶é“¾å¼é¢„æµ‹ï¼šåŸºäº AI çš„å®æ—¶é¢„æµ‹ï¼Œå±•ç¤ºæ½œåœ¨çš„çˆ†å‘æœºä¼š"
    ]

    for col, label, help_text in zip(header_cols, labels, header_explanations):
        col.markdown(f"**{label}**")
        # caption è¾ƒå°å­—ä½“æ˜¾ç¤ºè§£é‡Šï¼Œä¾¿äºç”¨æˆ·ç›´æ¥é˜…è¯»è¡¨å¤´å«ä¹‰
        col.caption(help_text)
    st.markdown("---")

    for row in table_data:
        c1, c2, c3, c4, c5, c6, c7 = st.columns([0.6, 0.8, 1.2, 0.6, 1.2, 1.5, 3])
        c1.markdown(f"#### {row['ticker']}")
        c2.caption(row['name'])
        c3.caption(row['phase'])

        rsi_val = row['rsi']
        c4.markdown(f":{'red' if rsi_val > 70 else 'blue' if rsi_val < 30 else 'green'}[**{rsi_val:.0f}**]")

        bias_pct = row['bias'] * 100
        bar_color = "#ff4b4b" if row['bias'] >= 0.25 else "#2ca02c" if row['bias'] >= 0 else "#1f77b4"
        c5.markdown(
            f"""<div style="background-color: {bar_color}22; border-radius: 4px; padding: 2px 8px;"><span style="color: {bar_color}; font-weight: bold;">{bias_pct:+.1f}%</span></div>""",
            unsafe_allow_html=True)

        fig = make_sparkline(row['df']['Close'])
        c6.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False}, key=f"chart_{row['ticker']}")

        with c7.container(height=150, border=False):
            st.markdown(row['ai_pred'])
        st.divider()

    st.caption("æ³¨ï¼šAI é¢„æµ‹åŸºäº Google Search å®æ—¶æ£€ç´¢ã€‚é‡åŒ–æŒ‡æ ‡æ¯å°æ—¶æ›´æ–°ã€‚")
else:
    st.info("è¯·åœ¨å·¦ä¾§æ·»åŠ æ ‡çš„æˆ–ç‚¹å‡» AI æ‰«æã€‚")
